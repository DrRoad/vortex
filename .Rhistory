<<<<<<< HEAD
d$anomaly <- d$x - norms$x[norms$y==1]
norms$anomaly <- norms$x - norms$x[norms$y==1]
d$y[abs(d$anomaly)>(norms$anomaly[norms$y==2]) & d$y==1] <- 3
z <- length(d$y[d$y==3])
ggplot(d, aes(year, anomaly, color=factor(y))) +
geom_point(size=3) +
geom_segment(data=norms, aes(x=start, xend=end, y=anomaly, yend=anomaly, color=factor(y))) +
geom_segment(data=norms, aes(x=1950, xend=1979, y=anomaly, yend=anomaly, color=factor(y)), linetype=2) +
geom_segment(data=norms, aes(x=1950, xend=1979, y=anomaly*-1, yend=anomaly*-1, color=factor(y)), linetype=2) +
scale_color_manual(values=c("black", "darkred", "blue")) +
theme(line=element_blank(), rect=element_blank(), legend.position="none") +
annotate(geom="text", x=1995, y=-5, label=paste0("Typicality of recent normal:\n", z, "/30 = ", round(z/30, 2)), hjust=.5, color="blue", size=5) +
labs(y="Anomaly: Min. temp. of coldest month (deg C)")
set.seed(112213)
x1 <- rnorm(30, 5, 2)
set.seed(111213)
x2 <- rnorm(30, 10, 2)
d=data.frame(x=c(x1, x2), y=rep(1:2, each=30), year=1950:2009)
norms <- d %>%
group_by(y) %>%
summarize(x=mean(x),
start=min(year),
end=max(year))
d$anomaly <- d$x - norms$x[norms$y==1]
norms$anomaly <- norms$x - norms$x[norms$y==1]
d$y[abs(d$anomaly)>(norms$anomaly[norms$y==2]) & d$y==1] <- 3
z <- length(d$y[d$y==3])
ggplot(d, aes(year, anomaly, color=factor(y))) +
geom_point(size=3) +
geom_segment(data=norms, aes(x=start, xend=end, y=anomaly, yend=anomaly, color=factor(y))) +
geom_segment(data=norms, aes(x=1950, xend=1979, y=anomaly, yend=anomaly, color=factor(y)), linetype=2) +
geom_segment(data=norms, aes(x=1950, xend=1979, y=anomaly*-1, yend=anomaly*-1, color=factor(y)), linetype=2) +
scale_color_manual(values=c("black", "darkred", "blue")) +
theme(line=element_blank(), rect=element_blank(), legend.position="none") +
annotate(geom="text", x=1995, y=-5, label=paste0("Typicality of recent normal:\n", z, "/30 = ", round(z/30, 2)), hjust=.5, color="blue", size=5) +
labs(y="Anomaly: Min. temp. of coldest month (deg C)")
set.seed(112213)
x1 <- rnorm(30, 5, 2)
set.seed(111213)
x2 <- rnorm(30, 11, 2)
d=data.frame(x=c(x1, x2), y=rep(1:2, each=30), year=1950:2009)
norms <- d %>%
group_by(y) %>%
summarize(x=mean(x),
start=min(year),
end=max(year))
d$anomaly <- d$x - norms$x[norms$y==1]
norms$anomaly <- norms$x - norms$x[norms$y==1]
d$y[abs(d$anomaly)>(norms$anomaly[norms$y==2]) & d$y==1] <- 3
z <- length(d$y[d$y==3])
ggplot(d, aes(year, anomaly, color=factor(y))) +
geom_point(size=3) +
geom_segment(data=norms, aes(x=start, xend=end, y=anomaly, yend=anomaly, color=factor(y))) +
geom_segment(data=norms, aes(x=1950, xend=1979, y=anomaly, yend=anomaly, color=factor(y)), linetype=2) +
geom_segment(data=norms, aes(x=1950, xend=1979, y=anomaly*-1, yend=anomaly*-1, color=factor(y)), linetype=2) +
scale_color_manual(values=c("black", "darkred", "blue")) +
theme(line=element_blank(), rect=element_blank(), legend.position="none") +
annotate(geom="text", x=1995, y=-5, label=paste0("Typicality of recent normal:\n", z, "/30 = ", round(z/30, 2)), hjust=.5, color="blue", size=5) +
labs(y="Anomaly: Min. temp. of coldest month (deg C)")
shiny::runApp('Documents/vortex/shiny/app1')
p <- arrangeGrob(plot(1,1), plot(1,1))
p
dev.off()
p <- arrangeGrob(plot(1,1), plot(1,1))
shiny::runApp('Documents/vortex/shiny/app1')
?png
runApp('Documents/vortex/shiny/app1')
shiny::runApp('Documents/vortex/shiny/app1')
?downloadButton
shiny::runApp('Documents/vortex/shiny/app1')
runApp('Documents/vortex/shiny/app1')
runApp('Documents/vortex/shiny/app1')
runApp('Documents/vortex/shiny/app1')
beforeparens(input$envvar)
runApp('Documents/vortex/shiny/app1')
p1 <- ggplot(data.frame(x=1,y=1), aes(x,y)) + geom_point()
p1
?par
par(mfrow=c(1,2))
plot(1,1)
plot(1,1)
plot(1,1)
plot(1,1)
dev.off()
plot(1,1)
plot.new()
plot(1,1)
dev.off()
p2 <- plot(1,1)
plot.new()
vp.map <- viewport(height=unit(1, "npc"), width=unit(0.6, "npc"),
just=c("left","top"),
y=1, x=0.4)
plot(1,1, vp=vp.map)
plot.new()
plot.new()
vp.map <- viewport(height=unit(1, "npc"), width=unit(0.6, "npc"),
just=c("left","top"),
y=1, x=0.4)
plot(1,1, vp=vp.map)
plot.new()
vp.map <- viewport(height=unit(1, "npc"), width=unit(0.6, "npc"),
just=c("left","top"),
y=1, x=0.4)
print(plot(1,1), vp=vp.map)
plot.new()
vp.map <- viewport(height=unit(1, "npc"), width=unit(0.6, "npc"),
just=c("left","top"),
y=1, x=0.4)
print(plot(1,1), vp=vp.map)
plot.new()
vp.map <- viewport(height=unit(1, "npc"), width=unit(0.6, "npc"),
just=c("left","top"),
y=1, x=0.4)
print(p1, vp=vp.map)
plot.new()
vp.scatter <- viewport(height=unit(1, "npc"), width=unit(0.4, "npc"),
just=c("left","top"),
y=1, x=0)
vp.map <- viewport(height=unit(1, "npc"), width=unit(0.6, "npc"),
just=c("left","top"),
y=1, x=0.4)
print(p1, vp=vp.scatter)
dev.off()
plot.new()
vp.scatter <- viewport(height=unit(1, "npc"), width=unit(0.4, "npc"),
just=c("left","top"),
y=1, x=0)
vp.map <- viewport(height=unit(1, "npc"), width=unit(0.6, "npc"),
just=c("left","top"),
y=1, x=0.4)
print(p1, vp=vp.scatter)
print(plot(1,1), vp=vp.map)
?pushViewport
plot.new()
vp.scatter <- viewport(height=unit(1, "npc"), width=unit(0.4, "npc"),
just=c("left","top"),
y=1, x=0)
vp.map <- viewport(height=unit(1, "npc"), width=unit(0.6, "npc"),
just=c("left","top"),
y=1, x=0.4)
print(p1, vp=vp.scatter)
pushViewport(vp.map)
plot(1,1)
?viewport
p2 <- plot(1,1)
plot.new()
vp.scatter <- viewport(height=unit(1, "npc"), width=unit(0.4, "npc"),
just=c("left","top"),
y=1, x=0)
vp.map <- viewport(height=unit(1, "npc"), width=unit(0.6, "npc"),
just=c("left","top"),
y=1, x=0.4)
print(p2, vp=vp.scatter)
plot.new()
vp.scatter <- viewport(height=unit(1, "npc"), width=unit(0.4, "npc"),
just=c("left","top"),
y=1, x=0)
vp.map <- viewport(height=unit(1, "npc"), width=unit(0.6, "npc"),
just=c("left","top"),
y=1, x=0.4)
plot(p1, vp=vp.scatter)
pushViewport(vp.map)
grid.rect()
plot(1,1)
popViewport(2)
plot.new()
vp.scatter <- viewport(height=unit(1, "npc"), width=unit(0.4, "npc"),
just=c("left","top"),
y=1, x=0)
vp.map <- viewport(height=unit(1, "npc"), width=unit(0.6, "npc"),
just=c("left","top"),
y=1, x=0.4)
plot(p1, vp=vp.scatter)
pushViewport(vp.map)
grid.rect()
par(plt = gridPLT(), new=TRUE)
plot(1,1)
popViewport(2)
library(gridBase)
plot.new()
vp.scatter <- viewport(height=unit(1, "npc"), width=unit(0.4, "npc"),
just=c("left","top"),
y=1, x=0)
vp.map <- viewport(height=unit(1, "npc"), width=unit(0.6, "npc"),
just=c("left","top"),
y=1, x=0.4)
plot(p1, vp=vp.scatter)
pushViewport(vp.map)
grid.rect()
par(plt = gridPLT(), new=TRUE)
plot(1,1)
popViewport(2)
plot.new()
vp.scatter <- viewport(height=unit(1, "npc"), width=unit(0.4, "npc"),
just=c("left","top"),
y=1, x=0)
vp.map <- viewport(height=unit(1, "npc"), width=unit(0.6, "npc"),
just=c("left","top"),
y=1, x=0.4)
plot(p1, vp=vp.scatter)
pushViewport(vp.map)
grid.rect()
par(plt = gridPLT(), new=TRUE)
plot(1,1)
runApp('Documents/vortex/shiny/app1')
runApp('Documents/vortex/shiny/app1')
runApp('Documents/vortex/shiny/app1')
runApp('Documents/vortex/shiny/app1')
runApp('Documents/vortex/shiny/app1')
runApp('Documents/vortex/shiny/app1')
runApp('Documents/vortex/shiny/app1')
runApp('Documents/vortex/shiny/app1')
str(e)
vars
runApp('Documents/vortex/shiny/app1')
runApp('Documents/vortex/shiny/app1')
runApp('Documents/vortex/shiny/app1')
library(dplyr)
library(tidyr)
library(maps)
library(mapproj)
library(stringr)
# load data
ds <- read.csv("data/cleanedsocial.csv", stringsAsFactors=F) %>%
mutate(fips = as.integer(paste0(state_fips, str_pad(county_fips, 3, "left", 0)))) %>%
select(-STNAME, -CTYNAME, -state_fips, -county_fips, -land_area)
dr <- read.csv("data/cleanedrisk.csv", stringsAsFactors=F) %>%
#select(-land_area) %>%
mutate(state_fips=as.integer(state_fips),
county_fips=as.integer(county_fips)) %>%
mutate(fips = as.integer(paste0(state_fips, str_pad(county_fips, 3, "left", 0)))) %>%
select(-CTYNAME, -state_fips, -county_fips)
# fips-to-name dictionary from maps library;
FIPS <- maps::county.fips
FIPS$polyname <- as.character(FIPS$polyname)
FIPS$polyname[FIPS$polyname=="florida,miami-dade"] <- "florida,dade"
# a clean counties table with the proper number and order of counties for plotting
cty <- readRDS("data/counties.rds") %>%
mutate(polyname = name) %>%
select(polyname) %>%
left_join(., FIPS) %>%
mutate(ID=1:length(polyname))
#if(!all.equal(ds$fips, dr$fips)) stop("social and risk data are misaligned")
e <- cbind(dr, select(ds, -fips))
fill <- function(x) na.omit(x)[1]
e <- left_join(cty, e) %>%
group_by(ID) %>%
summarise_each(funs(fill)) %>%
ungroup() %>%
filter(!duplicated(ID))
#if(!all.equal(cty$fips, e$fips)) stop("incorrect county structure")
e <- as.data.frame(e)
# fill in some missing values -- this is a patch that should maybe be transferred to the data prep scripts
na2min <- function(x){
x[is.na(x) | x<0] <- min(na.omit(x[x>=0]))
return(x)
}
e <- mutate_each_(e, funs(na2min), names(e)[grepl("tot_intensity", names(e))]) %>%
mutate(population_density = TOTPOP/land_area,
Income_Dollars = as.integer(as.character(sub(",", "", Income_Dollars))))
# variable names dictionary and translation functions
vars <- read.csv("data/variable_names", stringsAsFactors=F) %>%
filter(category != "other") %>%
arrange(desc(category), display)
r2d <- function(x) vars$display[match(x, vars$raw)]
d2r <- function(x) vars$raw[match(x, vars$display)]
g2r <- function(x) vars$raw[match(x, vars$group)]
# fake inputs for dev/debugging -- not used
input <- list(xv=vars$display[vars$category=="social"][1],
yv=vars$display[vars$category=="risk"][1],
xscale="linear",
yscale="linear",
smoother="none",
region="USA",
palette="inferno",
transpose_palette=F,
groups=na.omit(vars$group[vars$group!=""])[1:2],
envvar=vars$display[vars$category=="risk"][1],
scale="linear",
histogram_region="USA")
beforeparens <- function(x){
if(grepl("\\(", x)) return(substr(x, 1, regexpr("\\(", x)[1]-2))
return(x)}
capfirst <- function(x) paste0(toupper(substr(x,1,1)), substr(x,2,nchar(x)))
s <- data.frame(e[,g2r(input$groups)])
s <- as.data.frame(as.matrix(s) * e$TOTPOP)
if(ncol(s)==1) names(s) <- g2r(input$groups)
names(s) <- input$groups
v <- e[,d2r(input$envvar)]
if(class(v)=="factor") v <- as.character(v)
v <- as.numeric(v)
g <- data.frame(state=as.character(e$STNAME)) %>%
cbind(v) %>%
cbind(s) %>%
tidyr::gather(group, pop, -v, -state) %>%
dplyr::group_by(group) %>%
mutate(prop_pop = pop / sum(na.omit(pop)),
group=factor(group)) %>%
na.omit()
if(input$histogram_region != "USA") g <- filter(g, state==input$histogram_region)
m <- group_by(g(), group) %>% dplyr::summarize(wmean = weighted.mean(v, pop))
m <- group_by(g, group) %>% dplyr::summarize(wmean = weighted.mean(v, pop))
m
ggplot(g(), aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_density(adjust=2, alpha=.2, size=.75) +
geom_vline(data=m(), aes(xintercept=wmean, color=factor(group)), size=1.5) +
theme_minimal() +
theme(axis.text.y=element_blank(),
text=element_text(size=20),
legend.position="top") +
labs(x=input$envvar,
y="\nrelative proportion of group",
color="group", fill="group")
ggplot(g, aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_density(adjust=2, alpha=.2, size=.75) +
geom_vline(data=m, aes(xintercept=wmean, color=factor(group)), size=1.5) +
theme_minimal() +
theme(axis.text.y=element_blank(),
text=element_text(size=20),
legend.position="top") +
labs(x=input$envvar,
y="\nrelative proportion of group",
color="group", fill="group")
dev.off()
ggplot(g, aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_density(adjust=2, alpha=.2, size=.75) +
geom_vline(data=m, aes(xintercept=wmean, color=factor(group)), size=1.5) +
theme_minimal() +
theme(axis.text.y=element_blank(),
text=element_text(size=20),
legend.position="top") +
labs(x=input$envvar,
y="\nrelative proportion of group",
color="group", fill="group")
head(g)
ggplot(g(), aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_density(adjust=2, alpha=.2, size=.75)
ggplot(g, aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_density(adjust=2, alpha=.2, size=.75)
dev.off()
dev.off()
ggplot(g, aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_density(adjust=2, alpha=.2, size=.75)
?gridPLT
runApp('Documents/vortex/shiny/app1')
ggplot(g, aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_density(adjust=2, alpha=.2, size=.75)
ggplot(g, aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_area(alpha=.2, size=.75)
?geom_area
ggplot(g, aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_area(alpha=.2, size=.75, stat=..count..)
ggplot(g, aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_area(alpha=.2, size=.75, stat="count")
dev.off()
dev.off()
ggplot(g, aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_area(alpha=.2, size=.75, stat="count")
ggplot(g, aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_freqpoly(alpha=.2, size=.75)
?geom_freqpoly
ggplot(g, aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_freqpoly(alpha=.2, size=.75, stat="density")
ggplot(g, aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_freqpoly(size=.75, stat="density")
ggplot(g, aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_freqpoly(size=.75, stat=..density..)
ggplot(g, aes(v, ..density.., weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_freqpoly(size=.75)
ggplot(g, aes(v, ..density.., weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_freqpoly(size=.75, bins=20)
ggplot(g, aes(v, ..density.., weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_density(size=.75, bins=20)
ggplot(g, aes(v, ..density.., weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_density(size=.75)
ggplot(g, aes(v, ..density.., weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_density(size=.75, alpha=.5)
ggplot(g, aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_density(size=.75, alpha=.5)
g <- g() %>%
group_by(group) %>%
mutate(prop_pop = prop_pop/sum(na.omit(prop_pop)))
g <- g() %>%
group_by(group) %>%
mutate(prop_pop = prop_pop/sum(na.omit(prop_pop)))
g <- g %>%
group_by(group) %>%
mutate(prop_pop = prop_pop/sum(na.omit(prop_pop)))
ggplot(g, aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_density(adjust=2, alpha=.2, size=.75)
g <- g() %>%
#group_by(group) %>%
mutate(prop_pop = prop_pop/sum(na.omit(prop_pop)))
g <- g %>%
#group_by(group) %>%
mutate(prop_pop = prop_pop/sum(na.omit(prop_pop)))
ggplot(g(), aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_density(adjust=2, alpha=.2, size=.75)
ggplot(g, aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_density(adjust=2, alpha=.2, size=.75)
ggplot(g, aes(v, weight=prop_pop/sum(prop_pop), color=factor(group), fill=factor(group))) +
geom_density(adjust=2, alpha=.2, size=.75)
s <- data.frame(e[,g2r(input$groups)])
s <- as.data.frame(as.matrix(s) * e$TOTPOP)
if(ncol(s)==1) names(s) <- g2r(input$groups)
names(s) <- input$groups
v <- e[,d2r(input$envvar)]
if(class(v)=="factor") v <- as.character(v)
v <- as.numeric(v)
g <- data.frame(state=as.character(e$STNAME)) %>%
cbind(v) %>%
cbind(s) %>%
tidyr::gather(group, pop, -v, -state) %>%
dplyr::group_by(group) %>%
mutate(prop_pop = pop / sum(na.omit(pop)),
group=factor(group)) %>%
na.omit()
ggplot(g(), aes(v, weight=prop_pop/sum(prop_pop), color=factor(group), fill=factor(group))) +
geom_density(adjust=2, alpha=.2, size=.75)
ggplot(g, aes(v, weight=prop_pop/sum(prop_pop), color=factor(group), fill=factor(group))) +
geom_density(adjust=2, alpha=.2, size=.75)
ggplot(g(), aes(v, weight=prop_pop/sum(prop_pop, na.rm-T), color=factor(group), fill=factor(group))) +
geom_density(adjust=2, alpha=.2, size=.75)
ggplot(g(), aes(v, weight=prop_pop/sum(prop_pop, na.rm=T), color=factor(group), fill=factor(group))) +
geom_density(adjust=2, alpha=.2, size=.75)
ggplot(g, aes(v, weight=prop_pop/sum(prop_pop, na.rm=T), color=factor(group), fill=factor(group))) +
geom_density(adjust=2, alpha=.2, size=.75)
ggplot(g, aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_histogram(stat="density", alpha=.2, size=.75)
ggplot(g, aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_histogram(stat=..density.., alpha=.2, size=.75)
ggplot(g, aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_histogram(stat="density", alpha=.2, size=.75)
ggplot(g, aes(v, weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_histogram()
ggplot(g, aes(v, ..density.., weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_histogram()
ggplot(g, aes(v, ..density.., weight=prop_pop, color=factor(group), fill=factor(group))) +
geom_histogram(position="identity", alpha=.2)
ggplot() +
geom_density(data=g(),
aes(v, ..density.., weight=prop_pop, color=factor(group), fill=factor(group)),
adjust=2, alpha=.2, size=.75, position="identity")
ggplot() +
geom_density(data=g,
aes(v, ..density.., weight=prop_pop, color=factor(group), fill=factor(group)),
adjust=2, alpha=.2, size=.75, position="identity")
runApp('Documents/vortex/shiny/app1')
ggplot() +
geom_freqpoly(data=g(),
aes(v, ..density.., weight=prop_pop, color=factor(group), fill=factor(group)),
alpha=1, size=.5, bins=15, position="identity")
ggplot() +
geom_freqpoly(data=g,
aes(v, ..density.., weight=prop_pop, color=factor(group), fill=factor(group)),
alpha=1, size=.5, bins=15, position="identity")
ggplot() +
geom_area(data=g(),
aes(v, ..density.., weight=prop_pop, color=factor(group), fill=factor(group)),
alpha=1, size=.5, bins=15, position="identity", stat="bin")
ggplot() +
geom_area(data=g,
aes(v, ..density.., weight=prop_pop, color=factor(group), fill=factor(group)),
alpha=1, size=.5, bins=15, position="identity", stat="bin")
runApp('Documents/vortex/shiny/app1')
runApp('Documents/vortex/shiny/app1')
runApp('Documents/vortex/shiny/app1')
names(e)
str(e)
runApp('Documents/vortex/shiny/app1')
source('~/Documents/vortex/code/tornado_wind_hail.R', echo=TRUE)
files
files <- list.files("raw_data/tornado_wind_hail", pattern="\\.csv", full.names=T)
files
setwd("~/documents/vortex")
files <- list.files("raw_data/tornado_wind_hail", pattern="\\.csv", full.names=T)
names(files) <- c("hail", "tornado", "wind")
source('~/Documents/vortex/code/tornado_wind_hail.R', echo=TRUE)
d <- lapply(files, load_data)
d <- lapply(files[1], load_data)
path=files[1]
path
d <- read.csv(path, header=F, stringsAsFactors=F)
path=files[2]
d <- read.csv(path, header=F, stringsAsFactors=F)
path=files[3]
d <- read.csv(path, header=F, stringsAsFactors=F)
head(d)
files
read.csv(files[2])
read.csv(files[1])
read.csv(files[3])
download.file("http://www.spc.noaa.gov/wcm/data/Actual_tornadoes.csv",
"raw_data/tornado_wind_hail/tornado_raw.csv")
download.file("http://www.spc.noaa.gov/wcm/data/1955-2015_wind.csv.zip",
"raw_data/tornado_wind_hail/wind_raw.csv.zip")
download.file("http://www.spc.noaa.gov/wcm/data/1955-2015_hail.csv.zip",
"raw_data/tornado_wind_hail/hail_raw.csv.zip")
?unzip
unzip("raw_data/tornado_wind_hail/wind_raw.zip")
unzip("raw_data/tornado_wind_hail/wind_raw.zip")
unz("raw_data/tornado_wind_hail/wind_raw.zip")
?uzip
?unzip
?unzip
unzip("raw_data/tornado_wind_hail/wind_raw.zip", exdir="raw_data/tornado_wind_hail/")
unzip("raw_data/tornado_wind_hail/hail_raw.zip", exdir="raw_data/tornado_wind_hail/")
files <- list.files("raw_data/tornado_wind_hail", pattern="\\.csv", full.names=T)
fiels
files
names(files) <- c("hail", "wind", "tornado")
=======
leftmax<-LM(x)
rightmax<-RM(x)
for (i in 1:length(x)){
if (leftmax[i] > x[i] | rightmax[i]> x[i])  { depths[i]<-(min(leftmax[i], rightmax[i]) - x[i])}
}
return(depths)}
watershed(counts)
watershed<-function(x) {
depths<- as.vector(NULL)
leftmax<-LM(x)
rightmax<-RM(x)
for (i in 1:length(x)){
if (leftmax[i] > x[i] | rightmax[i]> x[i])  { depths[i]<-(min(leftmax[i], rightmax[i]) - x[i])}
}
return(depths)}
sum(watershed(counts))
watershed(counts)
watershed<-function(x) {
depths<- as.vector(NULL)
leftmax<-LM(x)
rightmax<-RM(x)
for (i in 1:length(x)){
if (leftmax[i] > x[i] | rightmax[i]> x[i])  { depths[i]<-(min(leftmax[i], rightmax[i]) - x[i])}
}
return(na.omit(depths))}
sum(watershed(counts))
barplot(counts)
counts<- c(7,3,2,4,6,8,4,5,8,1)
barplot(coutns)
barplot(counts)
sum(watershed(counts))
4+5+3+1+4+3
LM(counts)
RM(counts)
LM <- function(x) {
leftmax<-as.vector(NULL)
for (i in 1:length(x)){
leftmax[i]<-max(x[1:i]) }
return (leftmax) }
RM <- function(x) {
rightmax<-as.vector(NULL)
for (i in 1:length(x)){
rightmax[i]<-max(x[i:length(x)]) }
return (rightmax)}
RM(counts)
watershed<-function(x) {
depths<- as.vector(NULL)
leftmax<-LM(x)
rightmax<-RM(x)
for (i in 1:length(x)){
if (leftmax[i] > x[i] | rightmax[i]> x[i])  { depths[i]<-(min(leftmax[i], rightmax[i]) - x[i])}
}
return(na.omit(depths))}
sum(watershed(counts))
counts(1,2,3,4,5,4,3,2,1)
counts<-c(1,2,3,4,5,4,3,2,1)
sum(watershed(counts))
watershed<-function(x) {
depths<- as.vector(NULL)
leftmax<-LM(x)
rightmax<-RM(x)
for (i in 1:length(x)){
if (leftmax[i] > x[i] | rightmax[i]> x[i])  { depths[i]<-(min(leftmax[i], rightmax[i]) - x[i])}
}
return(sum(na.omit(depths)))}
watershed(counts)
counts<- c(1,3,2,4,6,8,4,5,8,1)
watershed(counts)
barplot(counts)
counts<- c(1,3,2,4,2,8,4,5,8,1)
watershed(counts)
barplot(counts)
counts<- c(10,3,2,4,2,8,4,5,8,7)
watershed(counts)
barplot(counts)
5+6+4+6+4+3
load("C:/Users/User1/Dropbox/Australian Ticks/forColin.rdata")
View(LizMatData)
summary(LizMatData)
seasons<- c("1", "2", "3", "4")
then season[item,]<- "winter"}
season[item,]= "winter"}
for (item in season) {
if item == "1"
season[item,]= "winter"}
season["1"]
seasons["1"]
seasons["1",]
seasons["1"]
seasons[,"1"]
seasons<- c("1", "2", "3", "4", "1", "2", "3", "4")
seasons[item,]= "winter"}
for (item in seasons) {
if item == "1"
seasons[item,]= "winter"}
for (item in seasons) {
if item == "1"  seasons[item,]= "winter"}
if (item == "1")  seasons[item,]= "winter"}
for (item in seasons) {
if (item == "1")  seasons[item,]= "winter"}
season[item]
seasons[item]
seasons[item,]
seasons[item]
for (item in seasons) {
if (item == "1")  seasons[item]= "winter"}
seasons
install.packages("nimble", repos = "http://r-nimble.org", type = "source")
install.packages("igraph")
install.packages("nimble", repos = "http://r-nimble.org", type = "source")
library(nimble)
install.packages("nimble")
install.packages("nimble", repos = "http://r-nimble.org", type = "source")
library(nimble)
library(nimble)
pumpCode <- nimbleCode({
for (i in 1:N){
theta[i] ~ dgamma(alpha,beta)
lambda[i] <- theta[i]*t[i]
x[i] ~ dpois(lambda[i])
}
alpha ~ dexp(1.0)
beta ~ dgamma(0.1,1.0)
})
pumpConsts <- list(N = 10,
t = c(94.3, 15.7, 62.9, 126, 5.24,
31.4, 1.05, 1.05, 2.1, 10.5))
pumpData <- list(x = c(5, 1, 5, 14, 3, 19, 1, 1, 4, 22))
pumpInits <- list(alpha = 1, beta = 1,
theta = rep(0.1, pumpConsts$N))
pump <- nimbleModel(code = pumpCode, name = 'pump', constants = pumpConsts,
data = pumpData, inits = pumpInits)
pump$getNodeNames()
plot(pump$graph)
install.packages(""adehabitat"")
install.packages("adehabitat")
c= c(0,1,2,3)
plot(c)
# read data set
fires <- read.csv('../../data/forestfires.csv')
# open graphic device
png(file = '../../images/scatterplot.png')
# Your code for the scatterplot
plot(fires$temp, fires$wind, type="p")
# close device
dev.off()
load("C:/Users/User1/Downloads/Export_Output_20150710_SFldHazAr.txt")
load("C:/Users/User1/Downloads/Export_Output_20150710_SFldHazAr.txt")
install.packages("babynames")
library(ggplot2)
myname <- subset(babynames, name == "Dana")
# find the most popular year for your name
myname$year[which.max(myname$n)]
# number of people with your name so far
sum(myname$n)
myname <- subset(babynames, name == "Dana")
# find the most popular year for your name
myname$year[which.max(myname$n)]
# number of people with your name so far
sum(myname$n)
library(babynames)
myname <- subset(babynames, name == "Dana")
# find the most popular year for your name
myname$year[which.max(myname$n)]
# number of people with your name so far
sum(myname$n)
ggplot(data = myname, aes(x = year, y = n, color = sex)) +
geom_line() +
theme_bw()
shiny::runApp('C:/Users/User1/Desktop/Stat259/ShinyApp')
dnorm(1,0,1)
plot(dnorm(0,1))
plot(dnorm(mean=0,sd=1))
plot(dnorm(1:100,mean=0,sd=1))
plot(dnorm(-100:100,mean=0,sd=1))
plot(dnorm(-10:10,mean=0,sd=1))
plot(dnorm(-1:1,mean=0,sd=1))
plot(dnorm(-3:3,mean=0,sd=1))
plot(dnorm(-5:5,mean=0,sd=1))
rbinom(100, p=.5)
rbinom(100, p=.5, 100)
rbinom(2, p=.5, 100)
rbinom(100, p=.5, 2)
rbinom(100, p=.5, 1)
mean(rbinom(100, p=.5, 1))
mean(rbinom(100, p=.5, 1))
mean(rbinom(100, p=.5, 1))
mean(rbinom(100, p=.5, 1))
mean(rbinom(100, p=.5, 1))
mean(rbinom(100, p=.5, 1))
mean(rbinom(100, p=.5, 1))
mean(rbinom(100, p=.5, 1))
mean(rbinom(100, p=.5, 1))
mean(rbinom(100, p=.5, 1))
mean(rbinom(100, p=.5, 1))
mean(rbinom(100, p=.5, 1))
mean(rbinom(100, p=.5, 1))
mean(rbinom(100, p=.5, 10))
rbinom(100, p=.5, 10)
rbinom(100, p=.5, 10)
rbinom(100, p=.5, 10)
plot(rbinom(100, p=.5, 10))
hist(rbinom(100, p=.5, 10))
install.packages('rgdal')
install.packages("dplyr","stringr", "rgdal", "raster", "rgeos")
library(stringr)
install.packages("dplyr")
install.packages("stringr")
install.packages("stringr")
install.packages(rgeos)
install.packages('rgeos')
install.packages('raster')
local({r <- getOption("repos"); r["CRAN"] <- "<https://cran.cnr.berkeley.edu/>"; options(repos=r)})
options(repos=structure(c(CRAN="https://cran.cnr.berkeley.edu/")))
get.Options
options("repos")
?install.packages
citation()
about()
R
licence()
version()
f <- function (x, a) (x - a)^2
f(3,2)
xmin <- optimize(f, c(0, 1), tol = 0.0001, a = 1/3)
xmin
setwd("C:/Users/User1/Desktop/Stat259/vortex/vortex")
library(rio) #used to import Excel files
install.packages('rio')
library(rio) #used to import Excel files
download.file("http://www.bea.gov/newsreleases/regional/lapi/2015/xls/lapi1115.xls","raw_data/poverty_unemployment_med_income/lapi1115.xls",method="curl")
download.file("http://www2.census.gov/geo/docs/reference/state.txt","raw_data/poverty_unemployment_med_income/state.txt")
download.file("http://www2.census.gov/geo/docs/reference/codes/files/national_county.txt","raw_data/poverty_unemployment_med_income/fips.csv")
####Make table of FIPS values####
state <- read.table("raw_data/poverty_unemployment_med_income/state.txt",sep="|",header=T,colClasses = "character")
state.abbrv <- subset(state,select = c(STUSAB,STATE_NAME) )
county <- read.csv("raw_data/poverty_unemployment_med_income/fips.csv",colClasses = "character",header=F)
names(county) <- c("STUSAB","state_fips","county_fips","county_name_full","fips_class")
fips.table <- merge(state.abbrv,county,by="STUSAB")
fips.table$state_county_fips <- paste(fips.table$state_fips,fips.table$county_fips,sep="")
discard.terr <- which(fips.table$STATE_NAME=="American Samoa"|fips.table$STATE_NAME=="Guam"|fips.table$STATE_NAME=="Northern Mariana Islands"|fips.table$STATE_NAME=="Puerto Rico"|fips.table$STATE_NAME=="U.S. Minor Outlying Islands"|fips.table$STATE_NAME=="U.S. Virgin Islands")
fips.table <- fips.table[-discard.terr,]
fips.table$lc_county_names <- fips.table$county_name_full
fips.table$lc_county_names <- tolower(fips.table$lc_county_names)
fips.table$lc_county_names[which(fips.table$STATE_NAME!="Virginia")] <- gsub(" county","",fips.table$lc_county_names)[which(fips.table$STATE_NAME!="Virginia")] #removes county from names, except for Virginia because Virginia is so odd.
fips.table$lc_county_names <- gsub(" parish","",fips.table$lc_county_names) #removes parish from names
fips.table <- fips.table[-which(fips.table$STUSAB == "DC"),]
per.cap.raw <- import("raw_data/poverty_unemployment_med_income/lapi1115.xls")
names(per.cap.raw) <- c("location","per.cap.2012","per.cap.2013","per.cap.2014","state.rank.per.cap.2014","percent.2013","percent.2014","state.rank.percent.2014")
per.cap.raw <- per.cap.raw[-which(is.na(per.cap.raw$per.cap.2012)|is.na(per.cap.raw$location)),] #removes rows that don't have data, leaving only states/counties.
if("United States" %in% per.cap.raw$location){per.cap.raw <- per.cap.raw[-(1:which(per.cap.raw$location=="United States")),]} #removes United States line
per.cap.raw[,"per.cap.2012"] <- as.numeric(per.cap.raw[,"per.cap.2012"])
per.cap.raw[,"per.cap.2013"] <- as.numeric(per.cap.raw[,"per.cap.2013"])
per.cap.raw[,"per.cap.2014"] <- as.numeric(per.cap.raw[,"per.cap.2014"])
per.cap.raw[,"state.rank.per.cap.2014"] <- as.numeric(per.cap.raw[,"state.rank.per.cap.2014"])
per.cap.raw[,"percent.2013"] <- as.numeric(per.cap.raw[,"percent.2013"])
per.cap.raw[,"percent.2014"] <- as.numeric(per.cap.raw[,"percent.2014"])
per.cap.raw[,"state.rank.percent.2014"] <- as.numeric(per.cap.raw[,"state.rank.percent.2014"])
####Adding state to the county rows####
per.cap.raw$STATE_NAME <- NA
state.rows <- which(is.na(per.cap.raw$state.rank.per.cap.2014)) #use if column weas convertic to numeric (NA inserted)
state.list <- per.cap.raw$location[state.rows]
st.begin <- state.rows; st.end <- c(state.rows[-1]-1,length(per.cap.raw$location))
state.range <- data.frame(st.begin,st.end) #ranges for each state's counties (all entries between states are from that state; they acted as headers in original document)
for (j in 1:length(state.list)) #using the row ranges for each state, labels counties accordingly.
{
per.cap.raw$STATE_NAME[state.range$st.begin[j]:state.range$st.end[j]] <- state.list[j]
}
####Removing specific errors, standardizing county names/capitalization####
per.cap.fix <- per.cap.raw #new DF, helps tracking for tracking errors if they occur
#States without systemic errors/spot-fixes
per.cap.fix$location <- gsub("Ã±","n",per.cap.fix$location) #official FIPS table does not use the accents
per.cap.fix$location[which(per.cap.fix$location=="Petersburg Borough" & per.cap.fix$STATE_NAME=="Alaska")] <- "Petersburg Census Area" #Petersburg not technically a borough, not listed as such in official FIPS list.
per.cap.fix$location[which(per.cap.fix$location=="Fremont (includes Yellowstone National Park)" & per.cap.fix$STATE_NAME=="Idaho")] <- "Fremont" #removes note from county name
per.cap.fix$location[which(per.cap.fix$location=="Oglala Lakota" & per.cap.fix$STATE_NAME=="South Dakota")] <- "Shannon" #county name changed in May 2015 and has not been updated in FIPS database
#Entries (from Virginia) that do not have "city" in them, but should.
per.cap.fix$location[which(per.cap.fix$location=="Alexandria" & per.cap.fix$STATE_NAME == "Virginia")] <- "Alexandria city"
per.cap.fix$location[which(per.cap.fix$location=="Chesapeake" & per.cap.fix$STATE_NAME == "Virginia")] <- "Chesapeake city"
per.cap.fix$location[which(per.cap.fix$location=="Hampton" & per.cap.fix$STATE_NAME == "Virginia")] <- "Hampton city"
per.cap.fix$location[which(per.cap.fix$location=="Newport News" & per.cap.fix$STATE_NAME == "Virginia")] <- "Newport News city"
per.cap.fix$location[which(per.cap.fix$location=="Norfolk" & per.cap.fix$STATE_NAME == "Virginia")] <- "Norfolk city"
per.cap.fix$location[which(per.cap.fix$location=="Portsmouth" & per.cap.fix$STATE_NAME == "Virginia")] <- "Portsmouth city"
per.cap.fix$location[which(per.cap.fix$location=="Suffolk" & per.cap.fix$STATE_NAME == "Virginia")] <- "Suffolk city"
per.cap.fix$location[which(per.cap.fix$location=="Virginia Beach" & per.cap.fix$STATE_NAME == "Virginia")] <- "Virginia Beach city"
#Entries that have merged smaller municipalities with larger (mostly Virginia); easier and less opaque than using a pattern-based fix.
#Note from full release (http://www.bea.gov/newsreleases/regional/lapi/2015/pdf/lapi1115.pdf): Virginia combination areas consist of one or two independent cities with populations of less than 100,000 combined with an adjacent county. The county name appears first, followed by the city name(s). Separate estimates for the jurisdictions making up the combination areas are not available.
#merged.index <- grep("\\+", per.cap.fix$location) #pulls locations with " +" in location name
#merged <- per.cap.fix[merged.index,] #useful to see what locations are, base replacements on, makes altering names further down
separated <- as.data.frame(matrix(data = NA, nrow=0, ncol = 9)) #dataframe to put un-merged municipalities into
names(separated) <- names(per.cap.fix)
#Separating municipalities (mostly Virginia; this strategy used for tranparency/easier troubleshooting)
Maui = per.cap.fix[which(per.cap.fix$location=="Maui + Kalawao"),]; Maui$location <- "Maui"
Kalawao = per.cap.fix[which(per.cap.fix$location=="Maui + Kalawao"),]; Kalawao$location <- "Kalawao"
Albemarle = per.cap.fix[which(per.cap.fix$location=="Albemarle + Charlottesville"),]; Albemarle$location <- "Albemarle"
Charlottesville.city = per.cap.fix[which(per.cap.fix$location=="Albemarle + Charlottesville"),]; Charlottesville.city$location <- "Charlottesville city"
Alleghany = per.cap.fix[which(per.cap.fix$location=="Alleghany + Covington"),]; Alleghany$location <- "Alleghany"
Covington.city = per.cap.fix[which(per.cap.fix$location=="Alleghany + Covington"),]; Covington.city$location <- "Covington city"
Augusta = per.cap.fix[which(per.cap.fix$location=="Augusta, Staunton + Waynesboro"),]; Augusta$location <- "Augusta"
Staunton.city = per.cap.fix[which(per.cap.fix$location=="Augusta, Staunton + Waynesboro"),]; Staunton.city$location <- "Staunton city"
Waynesboro.city = per.cap.fix[which(per.cap.fix$location=="Augusta, Staunton + Waynesboro"),]; Waynesboro.city$location <- "Waynesboro city"
Campbell = per.cap.fix[which(per.cap.fix$location=="Campbell + Lynchburg"),]; Campbell$location <- "Campbell"
Lynchburg.city = per.cap.fix[which(per.cap.fix$location=="Campbell + Lynchburg"),]; Lynchburg.city$location <- "Lynchburg city"
Carroll = per.cap.fix[which(per.cap.fix$location=="Carroll + Galax"),]; Carroll$location <- "Carroll"
Galax.city = per.cap.fix[which(per.cap.fix$location=="Carroll + Galax"),]; Galax.city$location <- "Galax city"
Dinwiddie = per.cap.fix[which(per.cap.fix$location=="Dinwiddie, Colonial Heights + Petersburg"),]; Dinwiddie$location <- "Dinwiddie"
Colonial.Heights.city = per.cap.fix[which(per.cap.fix$location=="Dinwiddie, Colonial Heights + Petersburg"),]; Colonial.Heights.city$location <- "Colonial Heights city"
Petersburg.city = per.cap.fix[which(per.cap.fix$location=="Dinwiddie, Colonial Heights + Petersburg"),]; Petersburg.city$location <- "Petersburg city"
Fairfax = per.cap.fix[which(per.cap.fix$location=="Fairfax, Fairfax City + Falls Church"),]; Fairfax$location <- "Fairfax"
Fairfax.city = per.cap.fix[which(per.cap.fix$location=="Fairfax, Fairfax City + Falls Church"),]; Fairfax.city$location <- "Fairfax city"
Falls.Church.city = per.cap.fix[which(per.cap.fix$location=="Fairfax, Fairfax City + Falls Church"),]; Falls.Church.city$location <- "Falls Church city"
Frederick = per.cap.fix[which(per.cap.fix$location=="Frederick + Winchester"),]; Frederick$location <- "Frederick"
Winchester.city = per.cap.fix[which(per.cap.fix$location=="Frederick + Winchester"),]; Winchester.city$location <- "Winchester city"
Greensville = per.cap.fix[which(per.cap.fix$location=="Greensville + Emporia"),]; Greensville$location <- "Greensville"
Emporia.city = per.cap.fix[which(per.cap.fix$location=="Greensville + Emporia"),]; Emporia.city$location <- "Emporia city"
Henry = per.cap.fix[which(per.cap.fix$location=="Henry + Martinsville"),]; Henry$location <- "Henry"
Martinsville.city = per.cap.fix[which(per.cap.fix$location=="Henry + Martinsville"),]; Martinsville.city$location <- "Martinsville city"
James.City = per.cap.fix[which(per.cap.fix$location=="James City + Williamsburg"),]; James.City$location <- "James City"
Williamsburg.city = per.cap.fix[which(per.cap.fix$location=="James City + Williamsburg"),]; Williamsburg.city$location <- "Williamsburg city"
Montgomery = per.cap.fix[which(per.cap.fix$location=="Montgomery + Radford"),]; Montgomery$location <- "Montgomery"
Radford.city = per.cap.fix[which(per.cap.fix$location=="Montgomery + Radford"),]; Radford.city$location <- "Radford city"
Pittsylvania= per.cap.fix[which(per.cap.fix$location=="Pittsylvania + Danville"),]; Pittsylvania$location <- "Pittsylvania"
Danville.city = per.cap.fix[which(per.cap.fix$location=="Pittsylvania + Danville"),]; Danville.city$location <- "Danville city"
Prince.George = per.cap.fix[which(per.cap.fix$location=="Prince George + Hopewell"),]; Prince.George$location <- "Prince George"
Hopewell.city = per.cap.fix[which(per.cap.fix$location=="Prince George + Hopewell"),]; Hopewell.city$location <- "Hopewell city"
Prince.William = per.cap.fix[which(per.cap.fix$location=="Prince William, Manassas + Manassas Park"),]; Prince.William$location <- "Prince William"
Manassas.city = per.cap.fix[which(per.cap.fix$location=="Prince William, Manassas + Manassas Park"),]; Manassas.city$location <- "Manassas city"
Manassas.Park.city = per.cap.fix[which(per.cap.fix$location=="Prince William, Manassas + Manassas Park"),]; Manassas.Park.city$location <- "Manassas Park city"
Roanoke.city = per.cap.fix[which(per.cap.fix$location=="Roanoke + Salem"),]; Roanoke.city$location <- "Roanoke city"
Salem.city = per.cap.fix[which(per.cap.fix$location=="Roanoke + Salem"),]; Salem.city$location <- "Salem city"
Rockbridge = per.cap.fix[which(per.cap.fix$location=="Rockbridge, Buena Vista + Lexington"),]; Rockbridge$location <- "Rockbridge"
Buena.Vista.city = per.cap.fix[which(per.cap.fix$location=="Rockbridge, Buena Vista + Lexington"),]; Buena.Vista.city$location <- "Buena Vista city"
Lexington.city = per.cap.fix[which(per.cap.fix$location=="Rockbridge, Buena Vista + Lexington"),]; Lexington.city$location <- "Lexington city"
Rockingham = per.cap.fix[which(per.cap.fix$location=="Rockingham + Harrisonburg"),]; Rockingham$location <- "Rockingham"
Harrisonburg.city = per.cap.fix[which(per.cap.fix$location=="Rockingham + Harrisonburg"),]; Harrisonburg.city$location <- "Harrisonburg city"
Southampton = per.cap.fix[which(per.cap.fix$location=="Southampton + Franklin"),]; Southampton$location <- "Southampton"
Franklin.city = per.cap.fix[which(per.cap.fix$location=="Southampton + Franklin"),]; Franklin.city$location <- "Franklin city"
Spotsylvania = per.cap.fix[which(per.cap.fix$location=="Spotsylvania + Fredericksburg"),]; Spotsylvania$location <- "Spotsylvania"
Fredericksburg.city = per.cap.fix[which(per.cap.fix$location=="Spotsylvania + Fredericksburg"),]; Fredericksburg.city$location <- "Fredericksburg city"
Washington = per.cap.fix[which(per.cap.fix$location=="Washington + Bristol"),]; Washington$location <- "Washington"
Bristol.city = per.cap.fix[which(per.cap.fix$location=="Washington + Bristol"),]; Bristol.city$location <- "Bristol city"
Wise = per.cap.fix[which(per.cap.fix$location=="Wise + Norton"),]; Wise$location <- "Wise"
Norton.city = per.cap.fix[which(per.cap.fix$location=="Wise + Norton"),]; Norton.city$location <- "Norton city"
York = per.cap.fix[which(per.cap.fix$location=="York + Poquoson"),]; York$location <- "York"
Poquoson.city = per.cap.fix[which(per.cap.fix$location=="York + Poquoson"),]; Poquoson.city$location <- "Poquoson city"
separated = rbind( #binds rows with fixed names
Maui,
Kalawao,
Albemarle,
Charlottesville.city,
Alleghany,
Covington.city,
Augusta,
Staunton.city,
Waynesboro.city,
Campbell,
Lynchburg.city,
Carroll,
Galax.city,
Dinwiddie,
Colonial.Heights.city,
Petersburg.city,
Fairfax,
Fairfax.city,
Falls.Church.city,
Frederick,
Winchester.city,
Greensville,
Henry,
Emporia.city,
Martinsville.city,
James.City, #for the record, it is "James City County". Because Virginia.
Williamsburg.city,
Montgomery,
Radford.city,
Pittsylvania,
Danville.city,
Prince.George,
Hopewell.city,
Prince.William,
Manassas.city,
Manassas.Park.city,
Roanoke.city,
Salem.city,
Rockbridge,
Buena.Vista.city,
Lexington.city,
Rockingham,
Harrisonburg.city,
Southampton,
Franklin.city,
Spotsylvania,
Fredericksburg.city,
Washington,
Bristol.city,
Wise,
Norton.city,
York,
Poquoson.city
)
per.cap.counties <- per.cap.fix[-which(is.na(per.cap.fix$state.rank.per.cap.2014)),] #removes state (and DC) entries from dataframe
if(("Albemarle" %in% per.cap.counties$location)==FALSE) {per.cap.counties <- rbind(per.cap.counties,separated)} #checks to make sure the separated counties haven't been added yet (admittedly arbitrary selection of county in VA, but one that doesn't share a name with any counties in other states.)
if(length(grep("\\+", per.cap.counties$location) != 0)) {per.cap.counties <- per.cap.counties[-grep("\\+", per.cap.counties$location),]} #removes the merged county names if they haven't been removed.
####Matching counties to FIPS table####
per.cap.counties$lc_county_names <- NA
per.cap.counties$lc_county_names <- tolower(per.cap.counties$location) #takes them to lowercase so they can be matched
fips.add <- merge(fips.table,per.cap.counties,by=c("STATE_NAME","lc_county_names"),all=T)
#check <- fips.add[which(is.na(fips.add$per.cap.2012)|is.na(fips.add$state_county_fips)),] #shows lines that have not merged appropriately; richmond/bedford virginia are both counties and cities, the cities not specifically mentioned in the per capita data.
####Pulling desired data####
categories <- c(
"state_county_fips",
"per.cap.2014"
)
#to match Valeri's original format, changing per.cap.2014 to Dollars
per.cap <- fips.add[,categories]
names(per.cap)[which(names(per.cap)=="per.cap.2014")] <- "Dollars"
write.csv(per.cap,"output/tidy_county_data/incomelower48.csv",row.names=F) #writes out cleaned data; preserved original cleaned file and columns name
download.file("http://www2.census.gov/geo/docs/reference/state.txt","raw_data/poverty_unemployment_med_income/state.txt")
download.file("http://www.census.gov/geo/docs/reference/state.txt","raw_data/poverty_unemployment_med_income/state.txt")
download.file("http://www2.census.gov/geo/docs/reference/codes/files/national_county.txt","raw_data/poverty_unemployment_med_income/fips.csv")
download.file("http://www2.census.gov/geo/docs/reference/state.txt","raw_data/poverty_unemployment_med_income/state.txt")
download.file("http://www.bea.gov/newsreleases/regional/lapi/2015/xls/lapi1115.xls","raw_data/poverty_unemployment_med_income/lapi1115.xls",method="curl")
download.file("http://www2.census.gov/geo/docs/reference/state.txt","raw_data/poverty_unemployment_med_income/state.txt")
state <- read.table("raw_data/poverty_unemployment_med_income/state.txt",sep="|",header=T,colClasses = "character")
state.abbrv <- subset(state,select = c(STUSAB,STATE_NAME) )
county <- read.csv("raw_data/poverty_unemployment_med_income/fips.csv",colClasses = "character",header=F)
names(county) <- c("STUSAB","state_fips","county_fips","county_name_full","fips_class")
download.file("http://www2.census.gov/geo/docs/reference/codes/files/national_county.txt","raw_data/poverty_unemployment_med_income/fips.csv")
county <- read.csv("raw_data/poverty_unemployment_med_income/fips.csv",colClasses = "character",header=F)
names(county) <- c("STUSAB","state_fips","county_fips","county_name_full","fips_class")
download.file("http://www.spc.noaa.gov/wcm/data/Actual_tornadoes.csv",
"raw_data/tornado_wind_hail/tornado_raw.csv")
download.file("http://www.spc.noaa.gov/wcm/data/1955-2015_wind.csv.zip",
"raw_data/tornado_wind_hail/wind_raw.zip")
download.file("http://www.spc.noaa.gov/wcm/data/1955-2015_hail.csv.zip",
"raw_data/tornado_wind_hail/hail_raw.zip")
unzip("raw_data/tornado_wind_hail/wind_raw.zip", exdir="raw_data/tornado_wind_hail/")
unzip("raw_data/tornado_wind_hail/hail_raw.zip", exdir="raw_data/tornado_wind_hail/")
?unzip
unzip("raw_data/tornado_wind_hail/wind_raw.zip", exdir = "raw_data/tornado_wind_hail/")
unzip("raw_data/tornado_wind_hail/hail_raw.zip", exdir = "raw_data/tornado_wind_hail/")
unzip("raw_data/tornado_wind_hail/wind_raw.zip", exdir = "raw_data/tornado_wind_hail")
unzip("raw_data/tornado_wind_hail/hail_raw.zip", exdir = "raw_data/tornado_wind_hail")
files <- list.files('output/tidy_county_data', full.names=T)
tables <- lapply(files, read.csv, stringsAsFactors=F)
# build a combined state_county_fips variable in tables that lack it
tables <- lapply(tables, function(x){
if(!'state_county_fips' %in% names(x)){
x$state_county_fips <- paste0(str_pad(x$state_fips, 2, 'left', 0),
str_pad(x$county_fips, 3, 'left', 0))
}else{
x$state_county_fips <- str_pad(x$state_county_fips, 5, 'left', 0)
}
return(x)
})
library(dplyr)
library(stringr)
library(rgdal)
library(raster)
library(rgeos)
library(dplyr)
library(stringr)
library(rgdal)
library(raster)
library(rgeos)
files <- list.files('output/tidy_county_data', full.names=T)
tables <- lapply(files, read.csv, stringsAsFactors=F)
# build a combined state_county_fips variable in tables that lack it
tables <- lapply(tables, function(x){
if(!'state_county_fips' %in% names(x)){
x$state_county_fips <- paste0(str_pad(x$state_fips, 2, 'left', 0),
str_pad(x$county_fips, 3, 'left', 0))
}else{
x$state_county_fips <- str_pad(x$state_county_fips, 5, 'left', 0)
}
return(x)
})
# add dataset-specific tag to dataset-specific variable names to avoid name conflicts
for(i in 1:length(tables)) names(tables[[i]])[!grepl('_fips', names(tables[[i]]))] <-
paste0(gsub('.csv', '', basename(files[i])), '...', names(tables[[i]])[!grepl('_fips', names(tables[[i]]))])
# merge datasets
master <- Reduce(full_join, tables)
# add county land area to table
counties <- readOGR('raw_data/census/us_counties_shapefile', 'cb_2014_us_county_500k')
counties <- crop(counties, extent(-126, -59, 22, 53)) # crop to US48
counties <- data.frame(state_county_fips=counties$GEOID,
land_area=gArea(counties, byid=T))
master <- left_join(master, counties)
files <- list.files('output/tidy_county_data', full.names=T)
tables <- lapply(files, read.csv, stringsAsFactors=F)
files <- list.files('output/tidy_county_data', full.names=T)
tables <- lapply(files, read.csv, stringsAsFactors=F)
# build a combined state_county_fips variable in tables that lack it
tables <- lapply(tables, function(x){
if(!'state_county_fips' %in% names(x)){
x$state_county_fips <- paste0(str_pad(x$state_fips, 2, 'left', 0),
str_pad(x$county_fips, 3, 'left', 0))
}else{
x$state_county_fips <- str_pad(x$state_county_fips, 5, 'left', 0)
}
return(x)
})
# add dataset-specific tag to dataset-specific variable names to avoid name conflicts
for(i in 1:length(tables)) names(tables[[i]])[!grepl('_fips', names(tables[[i]]))] <-
paste0(gsub('.csv', '', basename(files[i])), '...', names(tables[[i]])[!grepl('_fips', names(tables[[i]]))])
# merge datasets
master <- Reduce(full_join, tables)
# add county land area to table
counties <- readOGR('raw_data/census/us_counties_shapefile', 'cb_2014_us_county_500k')
counties <- crop(counties, extent(-126, -59, 22, 53)) # crop to US48
counties <- data.frame(state_county_fips=counties$GEOID,
land_area=gArea(counties, byid=T))
master <- left_join(master, counties)
>>>>>>> c72d9b7bf0a4865c2d87fe6123da5b6d79081f44
